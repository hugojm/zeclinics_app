{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis_BAT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.__version__ 1.2.4\n",
      "np.__version__ 1.20.3\n",
      "sns.__version__ 0.11.2\n",
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "print('pd.__version__', pd.__version__)\n",
    "print('np.__version__', np.__version__)\n",
    "print('sns.__version__', sns.__version__)\n",
    "\n",
    "print(pd.get_option(\"display.max_rows\"), \n",
    "    pd.get_option(\"display.max_columns\"), \n",
    "    pd.get_option(\"display.max_colwidth\"))\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "cwd = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images'\n",
    "cwd = '/Volumes/GoogleDrive/Shared drives/BATTELLE_2021_PART2/ZC_2021_JG_BATTELLE_PART2/VAST_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zetemplate done - plate xml is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total platefolders:  269 , zetemplate_done:  256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plate</th>\n",
       "      <th>zetemplate_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220423_1747_DM_R2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220402_1271_DM_R1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220402_1584_DM_R1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220405_1895_DM_R3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220423_1477_DM_R2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 plate zetemplate_done\n",
       "0  20220423_1747_DM_R2            True\n",
       "1  20220402_1271_DM_R1            True\n",
       "2  20220402_1584_DM_R1            True\n",
       "3  20220405_1895_DM_R3            True\n",
       "4  20220423_1477_DM_R2            True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zetemplate_done, zetemplate_pending = [], []\n",
    "for platefolder in os.listdir(cwd): \n",
    "    if os.path.isfile(os.path.join(cwd, platefolder, platefolder+'.xml')):\n",
    "        zetemplate_done.append(platefolder)\n",
    "    else:\n",
    "        zetemplate_pending.append(platefolder)        \n",
    "print('total platefolders: ', len(zetemplate_done)+len(zetemplate_pending), ', zetemplate_done: ', len(zetemplate_done))\n",
    "toDo_list = pd.DataFrame(data=zetemplate_done+zetemplate_pending, columns=['plate'])\n",
    "\n",
    "toDo_list.loc[toDo_list['plate'].isin(zetemplate_done), 'zetemplate_done'] = True\n",
    "toDo_list.head()\n",
    "# total platefolders:  210 , zetemplate_done:  201\n",
    "# total platefolders:  257 , zetemplate_done:  247\n",
    "# total platefolders:  267 , zetemplate_done:  254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read status csv - exclude excluded plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'EXCLUDED']\n",
      "23 plates excluded\n",
      "123 plates to analyse should have: 123\n"
     ]
    }
   ],
   "source": [
    "# BAT2_process_status_20201209_comments.csv - 15 plates excluded?\n",
    "# load latest status csv \n",
    "last_df = pd.read_csv(os.path.join(os.path.split(cwd)[0], 'BAT2_progress.csv'), sep=',')\n",
    "last_df = last_df[['EXCLUDED', 'plate_name']].copy()\n",
    "print(last_df['EXCLUDED'].unique())\n",
    "\n",
    "# excluded plates\n",
    "excluded_plates = last_df[last_df['EXCLUDED'].notnull()]['plate_name']\n",
    "print(len(excluded_plates), 'plates excluded')\n",
    "\n",
    "# plates to analyse\n",
    "plates2analyse = last_df[~last_df['plate_name'].isin(excluded_plates)]['plate_name']\n",
    "\n",
    "# ---- > analyse only DM not DS - already done\n",
    "plates2analyse = [item for item in plates2analyse if '_DS_' in item]\n",
    "\n",
    "# drop compound 1547\n",
    "#plates2analyse = [item for item in plates2analyse if '1547' not in item]\n",
    "\n",
    "print(len(plates2analyse), 'plates to analyse', 'should have:', 41*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phenotype children\n",
    "## every phenotype has a status \"finished\" if finished. \n",
    "\n",
    "***Boolean phenotypes***\n",
    "\n",
    "**value**: True or False\n",
    "\n",
    "- bodycurvature\n",
    "- snoutjawdefects\n",
    "- yolkedema\n",
    "- necrosis\n",
    "- tailbending\n",
    "- notochorddefects\n",
    "- craniofacialedema\n",
    "- finabsence\n",
    "- scoliosis\n",
    "\n",
    "***Measured phenotypes***\n",
    "\n",
    "- **fishoutline** \n",
    "    - **dorsal_image_area** \n",
    "    - **lateral_image_area**\n",
    "    - **unit** \"micron_square\"\n",
    "    \n",
    "Fishoutline is computed on the dorsal and lateral image.\n",
    "Fishoutline is prerequisite for all subsequent measured phenotypes.\n",
    "\n",
    "- **eyes** \n",
    "    - **dorsal_image_eye_down_length**\n",
    "    - **dorsal_image_eye_up_length**\n",
    "    - **unit** \"micron\"    \n",
    "    - eyes_down_params (eye pairs generated by algo, to toggle from)\n",
    "    - eyes_up_params (eye pairs generated by algo, to toggle from)\n",
    "    \n",
    "Eyes are quantified in dorsal images here, but may eventually be quantified in lateral images as well.\n",
    "For eyes the diameter length is measured from the selected ellipse. \n",
    "The ellipse is the one saved in the .roi file. \n",
    "It's not neccesarily present in eyes_down_params, eyes_up_params, as it may be user modified. \n",
    "\n",
    "- **pigmentation** \n",
    "    - **dorsal_image_area_fish_wo_eyes** area of the dorsal fish without eyes\n",
    "    - **dorsal_image_area_pigmentation** area of pigments \n",
    "    - **dorsal_image_area_ratio** ratio of pigments/ total area (fish without eyes)\n",
    "    - **unit** \"micron_square\"  \n",
    "    - **threshold** \"45\"\n",
    "\n",
    "for pigmentation eyes are generally excluded. Necrosis can lead to falsely detected pigmentation. \n",
    "Pigmentation area is derived here from applying a fixed threshold. For normalization it's to be seen if and which\n",
    "normalization will make sense (dorsal fish without eyes, bodylenght...)\n",
    "\n",
    "- **heart** \n",
    "    - **lateral_image_area**\n",
    "    - **unit** \"micron_square\"    \n",
    "\n",
    "- **bodylength** \n",
    "    - **lateral_image_length**  >\n",
    "    - **unit** \"micron\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventions: \n",
    "\n",
    "- There can be either dead24 OR dead120 selected in ZeTemplate. That is to signify the timepoint at which death was assessed and seen. Here mutually exclusive for 24 and 120. \n",
    "But for Battelle the fields are to signify simply whether an embryo is dead or alive at the timepoint. And here every embryo dead at 24 is also dead at 120 (we don't check for spontaneous reanimation...)\n",
    "\n",
    "\n",
    "# Their naming convention\n",
    "\n",
    "- **Axis: curvature of body axis** --> body_axis_defect\n",
    "- **Yolk sac: Edema** --> yolk_sac_edema\n",
    "\n",
    "\n",
    "- **Craniofacial: eye** defects --> unspecific, enlarged or decreased\n",
    "- **Craniofacial: snout jaw defects** --> snoutjawdefects\n",
    "- **Craniofacial: edema** --> craniofacial_edema\n",
    "\n",
    "\n",
    "- **Percardial tissue: Edema** --> pericardial_area enlarged\n",
    "\n",
    "\n",
    "- **Trunk: short** --> body_length decreased\n",
    "- **Trunk: long** --> body_length increased\n",
    "\n",
    "\n",
    "- **Pigment: abnormal** --> pigmentation increased or decreased\n",
    "- **Pigment: decreased** --> pigmentation decreased\n",
    "- **Pigment: absent** coloration --> pigmentation smaller than?? not clear --> nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- FUNCTIONS -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_attributes = [\"chorion\", \"exposure\", \"compound\", \"dose\", \"unit\", \"dead24\", \"dead120\", \"unhatched120\"\n",
    "                   , \"creation_date\", \"well_folder\", \"lateral_image\", \"dorsal_image\", \"show2user\", \"excluded\"\n",
    "                   , \"correction_done\"]\n",
    "\n",
    "booleans = ['bodycurvature', 'snoutjawdefects', 'yolkedema', 'necrosis', 'tailbending', 'notochorddefects'\n",
    "            , 'craniofacialedema', 'finabsence', 'scoliosis']\n",
    "\n",
    "measured = ['fishoutline', 'eyes', 'pigmentation', 'heart', 'bodylength']\n",
    "\n",
    "params_measured = {'fishoutline':['dorsal_image_area', 'lateral_image_area', 'unit']\n",
    "                   , 'eyes':['dorsal_image_eye_down_length', 'dorsal_image_eye_up_length']\n",
    "                   , 'pigmentation':['dorsal_image_area_fish_wo_eyes', 'dorsal_image_area_pigmentation', 'dorsal_image_area_ratio', 'unit', 'threshold']\n",
    "                   , 'heart':['lateral_image_area', 'unit']\n",
    "                   , 'bodylength':['lateral_image_length', 'unit']}\n",
    "\n",
    "\n",
    "def parse_xml_full(xml_path, well_attributes, booleans, measured, params_measured):\n",
    "    '''get all BAT2 phenotypes /values out - not checking for status here'''\n",
    "    rows = []\n",
    "    xtree = et.parse(xml_path)\n",
    "    xroot = xtree.getroot() \n",
    "    plate_name = xroot.attrib.get(\"plate_name\")\n",
    "    wells = []\n",
    "    \n",
    "    measured_cols = [item+'_'+att for item in list(params_measured.keys()) for att in list(params_measured[item])]\n",
    "    \n",
    "    cols = ['plate_name', 'name'] + well_attributes + booleans + measured_cols\n",
    "    \n",
    "    \n",
    "    for node in xroot: \n",
    "        well_name = node.attrib.get(\"name\")\n",
    "        wells.append(well_name)\n",
    "    \n",
    "    for well in wells: \n",
    "        d = {}\n",
    "        thiswell = xroot.find(\".//*[@name='\"+well+\"']\")\n",
    "        d['plate_name'] = plate_name\n",
    "        d['name']=well\n",
    "        \n",
    "        # general attributes \n",
    "        for item in well_attributes: \n",
    "            d[item] = thiswell.attrib.get(item)\n",
    "        \n",
    "        # boolean pts\n",
    "        for bo in booleans: \n",
    "            element = thiswell.find(bo)\n",
    "            if element != None:\n",
    "                d[bo] = element.get('value')\n",
    "            else: \n",
    "                d[bo] = 'None'\n",
    "           \n",
    "        # measured: \n",
    "        for me in measured: \n",
    "            element = thiswell.find(me)\n",
    "            for att in params_measured[me]:        \n",
    "                if element != None:\n",
    "                    d[me+'_'+att] = element.get(att)\n",
    "                else: \n",
    "                    d[me+'_'+att] = None\n",
    "        \n",
    "        # append the dict            \n",
    "        rows.append(d)\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns = cols)\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "    ## preprocess\n",
    "def preprocess(df1):\n",
    "    df = df1.copy()\n",
    "    # set well_name\n",
    "    df.rename(columns={'name':'well_name'}, inplace=True)\n",
    "\n",
    "    # make condtion column\n",
    "    df['condition'] = df['compound']+'_'+df['dose'].astype(str)+'_'+df['unit']\n",
    "\n",
    "    # pd to num\n",
    "    for col in df.columns: \n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    # get eye diameter mean\n",
    "    df['avg_eye_diameter'] = (df['eyes_dorsal_image_eye_down_length']+df['eyes_dorsal_image_eye_up_length'])/2\n",
    "    \n",
    "    # dead120 True if dead24 True\n",
    "    df.loc[df['dead24']==1, 'dead120'] = 1\n",
    "    \n",
    "    # set excluded wells value to nan\n",
    "    columns = list(df.columns)\n",
    "    col2keep = well_attributes + ['plate_name', 'well_name', 'condition']\n",
    "    col2nan = [c for c in columns if c not in col2keep]\n",
    "    df.loc[df['excluded']=='True', col2nan] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "def phenotype_from_continous(df1, neg_CTRL_identifier, phenotype_col, plot_stuff): \n",
    "    '''check a measured phenotype against negCtrl (searchstring) and provide battelle format output\n",
    "    return a figure if desired'''\n",
    "    df = df1.copy()\n",
    "    neg_CTRL_name = [name for name in df.condition if neg_CTRL_identifier in name][0]\n",
    "    grouped = df.groupby(['condition']).agg(['mean', 'std'])\n",
    "    \n",
    "    ul = grouped[(phenotype_col, 'mean')][neg_CTRL_name] + 2*grouped[(phenotype_col, 'std')][neg_CTRL_name]\n",
    "    ll = grouped[(phenotype_col, 'mean')][neg_CTRL_name] - 2*grouped[(phenotype_col, 'std')][neg_CTRL_name]\n",
    "    \n",
    "    #print('ll: ', ll, 'ul: ', ul)\n",
    "    \n",
    "    def enlarged_or_decreased(x, ul, ll):\n",
    "        if x > ul or x<ll:\n",
    "            return True\n",
    "        elif x < ul and x>ll:\n",
    "            return False\n",
    "        else: \n",
    "            return x\n",
    "    \n",
    "    def enlarged(x, ul, ll): \n",
    "        if x > ul: \n",
    "            return True\n",
    "        elif x < ul: \n",
    "            return False\n",
    "        else: return x\n",
    "    \n",
    "    def decreased(x, ul, ll): \n",
    "        if x < ll: \n",
    "            return True\n",
    "        elif x > ll: \n",
    "            return False\n",
    "        else: return x\n",
    "    \n",
    "    if phenotype_col == 'avg_eye_diameter':\n",
    "        #Craniofacial: eye defects --> unspecific, enlarged or decreased\n",
    "        df['Craniofacial: eye defects'] = df[phenotype_col].apply(lambda x: enlarged_or_decreased(x, ul, ll))        \n",
    "    #if phenotype_col == 'pigmentation_dorsal_image_area_pigmentation':\n",
    "    if 'pigmentation' in phenotype_col: \n",
    "        #'pigmentation_dorsal_image_area_pigmentation',\n",
    "        #'pigmentation_dorsal_image_area_ratio'\n",
    "        #Pigment: abnormal --> pigmentation increased or decreased\n",
    "        df['Pigment: abnormal'] = df[phenotype_col].apply(lambda x: enlarged_or_decreased(x, ul, ll))\n",
    "        df['Pigment: decreased'] = df[phenotype_col].apply(lambda x: decreased(x, ul, ll))\n",
    "        df['Pigment: absent coloration'] = np.nan\n",
    "    \n",
    "    if phenotype_col == 'heart_lateral_image_area':\n",
    "        #Percardial tissue: Edema --> pericardial_area enlarged\n",
    "        df['Percardial tissue: Edema'] = df[phenotype_col].apply(lambda x: enlarged(x, ul, ll))\n",
    "\n",
    "    if phenotype_col == 'bodylength_lateral_image_length':\n",
    "        #Trunk: short --> body_length decreased\n",
    "        #Trunk: long --> body_length increased\n",
    "        df['Trunk: short'] = df[phenotype_col].apply(lambda x: decreased(x, ul, ll))\n",
    "        df['Trunk: long'] = df[phenotype_col].apply(lambda x: enlarged(x, ul, ll))\n",
    "        \n",
    "    fig = None\n",
    "    if plot_stuff: \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = sns.boxplot(x = 'condition', y=phenotype_col, data=df[~df.condition.str.contains('DCA')], color='limegreen')\n",
    "        ax = sns.swarmplot(x = 'condition', y=phenotype_col, data=df[~df.condition.str.contains('DCA')], color='black')\n",
    "        ax.set_xlabel('')\n",
    "        labels = ax.get_xticklabels()\n",
    "        labels = [l.get_text() for l in labels]\n",
    "        labels = [l.replace('_', ' ') for l in labels]\n",
    "        ax.set_xticklabels(labels, rotation=90)\n",
    "        plt.axhline(y=float(ul), xmin=0, xmax=1, linestyle='--', color='magenta', lw=1)\n",
    "        plt.axhline(y=float(ll), xmin=0, xmax=1, linestyle='--', color='magenta', lw=1)\n",
    "    return fig, df\n",
    "#figure, df1 = phenotype_from_continous(df, 'DMSO', 'avg_eye_diameter', True)\n",
    "\n",
    "# pigmentation_dorsal_image_area_pigmentation, pigmentation_dorsal_image_area_ratio\n",
    "#figure, df1 = phenotype_from_continous(df, 'DMSO', 'pigmentation_dorsal_image_area_pigmentation', True) \n",
    "\n",
    "#figure, df1 = phenotype_from_continous(df, 'DMSO', 'heart_lateral_image_area', True) \n",
    "\n",
    "#figure, df1 = phenotype_from_continous(df, 'DMSO', 'bodylength_lateral_image_length', True) \n",
    "\n",
    "\n",
    "def phenotype_from_continous_different_neg_ctrl(df_comp, df_neg_ctrl, neg_CTRL_identifier, phenotype_col): \n",
    "    '''check a measured phenotype against a negCtrl (searchstring) ON A DIFFERENT PLATE and provide battelle format output'''\n",
    "    df = df_neg_ctrl.copy()\n",
    "    neg_CTRL_name = [name for name in df.condition if neg_CTRL_identifier in name][0]\n",
    "    grouped = df.groupby(['condition']).agg(['mean', 'std'])\n",
    "    \n",
    "    ul = grouped[(phenotype_col, 'mean')][neg_CTRL_name] + 2*grouped[(phenotype_col, 'std')][neg_CTRL_name]\n",
    "    ll = grouped[(phenotype_col, 'mean')][neg_CTRL_name] - 2*grouped[(phenotype_col, 'std')][neg_CTRL_name]\n",
    "    \n",
    "    #print('ll: ', ll, 'ul: ', ul)\n",
    "    \n",
    "    def enlarged_or_decreased(x, ul, ll):\n",
    "        if x > ul or x<ll:\n",
    "            return True\n",
    "        elif x < ul and x>ll:\n",
    "            return False\n",
    "        else: \n",
    "            return x\n",
    "    \n",
    "    def enlarged(x, ul, ll): \n",
    "        if x > ul: \n",
    "            return True\n",
    "        elif x < ul: \n",
    "            return False\n",
    "        else: return x\n",
    "    \n",
    "    def decreased(x, ul, ll): \n",
    "        if x < ll: \n",
    "            return True\n",
    "        elif x > ll: \n",
    "            return False\n",
    "        else: return x\n",
    "    \n",
    "    if phenotype_col == 'avg_eye_diameter':\n",
    "        #Craniofacial: eye defects --> unspecific, enlarged or decreased\n",
    "        df_comp['Craniofacial: eye defects'] = df_comp[phenotype_col].apply(lambda x: enlarged_or_decreased(x, ul, ll))        \n",
    "    #if phenotype_col == 'pigmentation_dorsal_image_area_pigmentation':\n",
    "    if 'pigmentation' in phenotype_col: \n",
    "        #'pigmentation_dorsal_image_area_pigmentation',\n",
    "        #'pigmentation_dorsal_image_area_ratio'\n",
    "        #Pigment: abnormal --> pigmentation increased or decreased\n",
    "        df_comp['Pigment: abnormal'] = df_comp[phenotype_col].apply(lambda x: enlarged_or_decreased(x, ul, ll))\n",
    "        df_comp['Pigment: decreased'] = df_comp[phenotype_col].apply(lambda x: decreased(x, ul, ll))\n",
    "        df_comp['Pigment: absent coloration'] = np.nan\n",
    "    \n",
    "    if phenotype_col == 'heart_lateral_image_area':\n",
    "        #Percardial tissue: Edema --> pericardial_area enlarged\n",
    "        df_comp['Percardial tissue: Edema'] = df_comp[phenotype_col].apply(lambda x: enlarged(x, ul, ll))\n",
    "\n",
    "    if phenotype_col == 'bodylength_lateral_image_length':\n",
    "        #Trunk: short --> body_length decreased\n",
    "        #Trunk: long --> body_length increased\n",
    "        df_comp['Trunk: short'] = df_comp[phenotype_col].apply(lambda x: decreased(x, ul, ll))\n",
    "        df_comp['Trunk: long'] = df_comp[phenotype_col].apply(lambda x: enlarged(x, ul, ll))\n",
    "        \n",
    "    return df_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- WORKFLOW -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate plate csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20211221_1271_DS_R3', '20220110_1271_DS_R5', '20220115_1271_DS_R6']\n",
      "0 working with:  20211127_1046_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "1 working with:  20211127_1694_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "2 working with:  20211127_1951_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "3 working with:  20211127_1956_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "4 working with:  20211129_1046_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "5 working with:  20211129_1694_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "6 working with:  20211129_1951_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "7 working with:  20211129_1956_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "8 working with:  20211204_1046_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "9 working with:  20211204_1694_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "10 working with:  20211204_1951_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "11 working with:  20211204_1956_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "12 working with:  20211221_1171_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "13 working with:  20211221_1271_DS_R3\n",
      "(96, 49)\n",
      "exists:  True\n",
      "14 working with:  20211227_1584_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "15 working with:  20211227_1728_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "16 working with:  20211227_1975_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "17 working with:  20220110_1171_DS_R5\n",
      "(96, 49)\n",
      "exists:  False\n",
      "18 working with:  20220110_1271_DS_R5\n",
      "(96, 49)\n",
      "exists:  True\n",
      "19 working with:  20220110_1584_DS_R5\n",
      "(96, 49)\n",
      "exists:  False\n",
      "20 working with:  20220110_1728_DS_R5\n",
      "(96, 49)\n",
      "exists:  False\n",
      "21 working with:  20220110_1975_DS_R5\n",
      "(96, 49)\n",
      "exists:  False\n",
      "22 working with:  20220115_1171_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "23 working with:  20220115_1271_DS_R6\n",
      "(96, 49)\n",
      "exists:  True\n",
      "24 working with:  20220115_1584_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "25 working with:  20220115_1728_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "26 working with:  20220115_1975_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "27 working with:  20220117_1437_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "28 working with:  20220117_1623_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "29 working with:  20220117_1770_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "30 working with:  20220117_1825_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "31 working with:  20220117_1895_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "32 working with:  20220129_1437_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "33 working with:  20220129_1623_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "34 working with:  20220129_1770_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "35 working with:  20220129_1825_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "36 working with:  20220129_1895_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "37 working with:  20220205_1437_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "38 working with:  20220205_1623_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "39 working with:  20220205_1770_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "40 working with:  20220205_1825_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "41 working with:  20220205_1895_DS_R6\n",
      "(96, 49)\n",
      "exists:  False\n",
      "42 working with:  20220207_1477_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "43 working with:  20220207_1547_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "44 working with:  20220207_1724_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "45 working with:  20220207_1747_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "46 working with:  20220207_1965_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "47 working with:  20220208_1036_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "48 working with:  20220208_1355_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "49 working with:  20220208_1625_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "50 working with:  20220208_1719_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "51 working with:  20220208_1978_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "52 working with:  20220212_1477_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "53 working with:  20220212_1965_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "54 working with:  20220214_1477_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "55 working with:  20220214_1547_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "56 working with:  20220214_1724_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "57 working with:  20220214_1965_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "58 working with:  20220215_1625_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "59 working with:  20220215_1719_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "60 working with:  20220215_1978_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "61 working with:  20220219_1111_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "62 working with:  20220219_1240_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "63 working with:  20220219_1247_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "64 working with:  20220219_1323_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "65 working with:  20220221_1111_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "66 working with:  20220221_1240_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "67 working with:  20220221_1247_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "68 working with:  20220221_1323_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "69 working with:  20220221_1656_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "70 working with:  20220222_1036_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "71 working with:  20220222_1355_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "72 working with:  20220222_1625_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "73 working with:  20220222_1719_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "74 working with:  20220222_1978_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "75 working with:  20220226_1111_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "76 working with:  20220226_1240_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "77 working with:  20220226_1247_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "78 working with:  20220226_1323_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "79 working with:  20220226_1656_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "80 working with:  20220228_1409_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "81 working with:  20220228_1630_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "82 working with:  20220228_1693_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "83 working with:  20220228_1771_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "84 working with:  20220228_1989_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "85 working with:  20220305_1409_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "86 working with:  20220305_1630_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "87 working with:  20220305_1693_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "88 working with:  20220305_1771_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "89 working with:  20220305_1989_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "90 working with:  20220307_1409_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "91 working with:  20220307_1771_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "92 working with:  20220307_1989_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "93 working with:  20220308_1072_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "94 working with:  20220308_1229_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "95 working with:  20220308_1454_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "96 working with:  20220308_1630_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "97 working with:  20220308_1794_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "98 working with:  20220308_1919_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "99 working with:  20220312_1072_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "100 working with:  20220312_1229_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "101 working with:  20220312_1454_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "102 working with:  20220312_1794_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "103 working with:  20220312_1919_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "104 working with:  20220314_1072_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "105 working with:  20220314_1229_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "106 working with:  20220314_1454_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "107 working with:  20220314_1794_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "108 working with:  20220314_1919_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "109 working with:  20220315_1200_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "110 working with:  20220315_1200_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "111 working with:  20220315_1693_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "112 working with:  20220315_1804_DS_R1\n",
      "(96, 49)\n",
      "exists:  False\n",
      "113 working with:  20220315_1804_DS_R2\n",
      "(96, 49)\n",
      "exists:  False\n",
      "114 working with:  20220319_1036_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "115 working with:  20220319_1200_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "116 working with:  20220319_1724_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "117 working with:  20220319_1747_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "118 working with:  20220319_1804_DS_R3\n",
      "(96, 49)\n",
      "exists:  False\n",
      "119 working with:  20220321_1355_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "120 working with:  20220321_1656_DS_R4\n",
      "(96, 49)\n",
      "exists:  False\n",
      "121 working with:  20220321_1747_DS_R5\n",
      "(96, 49)\n",
      "exists:  False\n",
      "122 working with:  20220523_1547_DS_R5\n",
      "(96, 49)\n",
      "exists:  True\n"
     ]
    }
   ],
   "source": [
    "# if we need to run only a subset of plates: \n",
    "\n",
    "subset_plates = [item for item in plates2analyse if '1271' in item]\n",
    "print(subset_plates)\n",
    "\n",
    "for p, plate in enumerate(plates2analyse): \n",
    "# for p, plate in enumerate(subset_plates): \n",
    "    path = os.path.join(cwd, plate, plate+'.xml')\n",
    "    print(p, 'working with: ', plate)\n",
    "    df = parse_xml_full(path, well_attributes, booleans, measured, params_measured)\n",
    "    df = preprocess(df)\n",
    "    # measured phenotypes\n",
    "    m =['avg_eye_diameter', 'bodylength_lateral_image_length'\n",
    "        , 'heart_lateral_image_area', 'pigmentation_dorsal_image_area_pigmentation']\n",
    "    for moo in m: \n",
    "        figure, df = phenotype_from_continous(df, 'DMSO', moo, False) \n",
    "    print(df.shape)\n",
    "    outdir = os.path.split(cwd)[0]\n",
    "    print('exists: ', os.path.isfile(os.path.join(outdir, 'plate_csvs', plate+'.csv')))\n",
    "    df.to_csv(os.path.join(outdir, 'plate_csvs', plate+'.csv'), sep=',', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkpoint - for complete analysis, run further\n",
    "\n",
    "# actually after saving to plate_csvs folder, run BAT2_Pack10compounds, then BAT2_squash_to_format"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee445c29dedd4a71891f2f1d193108c19b2304a51a0cdac7aa1b226577bad998"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('toxeco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
