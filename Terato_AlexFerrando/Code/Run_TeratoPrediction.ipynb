{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJmg38Dy6C_1"
   },
   "source": [
    "## Semantic segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "error",
     "timestamp": 1624285221379,
     "user": {
      "displayName": "Andrea Garcia Valdés",
      "photoUrl": "",
      "userId": "11425704364991342656"
     },
     "user_tz": -120
    },
    "id": "-iHeTjnQ6C_2",
    "outputId": "738abaf3-dc8a-4ed7-995d-07ec187aa843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sylviadyballa/repos/zeclinics_app/Terato_AlexFerrando/Code\n",
      "started\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports for the execution of the code.\n",
    "# Make sure you have previously executed requirements.txt\n",
    "\n",
    "'''\n",
    "# WARNING:\n",
    "\n",
    "Check https://pytorch.org/get-started/previous-versions/ and install the proper\n",
    "pytorch and torchvision versions according to your cuda version.\n",
    "\n",
    "You can figure out your cuda versions with:\n",
    "/usr/local/cuda/bin/nvcc --version\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import click\n",
    "import pickle\n",
    "import datahandler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import ETL_lib as Tox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils import data\n",
    "from trainer import train_model, train_clasif_model\n",
    "from model import createDeepLabv3_resnet_50, binary_fenotypes_wideresnet50\n",
    "from graphics import plots, Mca, doseresponse\n",
    "print('started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWHU9HoY6DAD"
   },
   "source": [
    "# Model usage\n",
    "\n",
    "Once we have trained the models, we can proceed by doing predictions over new plates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKTVQfmK6DAE"
   },
   "source": [
    "**Step 2 (Plate Predictions)**: Once we have our mask extraction and our boolean phenotypes models trained, we can now use them to predict over a plate. \n",
    "\n",
    "The following chunk of code will define the plate we want to analyze and will call the main function generate_and_save_predictions from the Tox library. This function saves the roi of each mask inside each corresponding Well folder and generats an overall stats.csv file for the entire plate, which has the predictions on the boolean phenotypes for each Well, among other data\n",
    "\n",
    "The input parameters to execute the predictions are:\n",
    "\n",
    "1. *plate_path*: Path to the plate to predict.\n",
    "2. *batch_size*: Size of the number of images to pass through the nets at the same time. 4 should be a good one.\n",
    "3. *model_path_seg*: Path to the semantic segmentation model  (Ends with .pt). \n",
    "4. *model_path_bools*: Path to the boolean phenotypes model  (Ends with .pt). \n",
    "5. *pheno_names*: Name of the different predicted phenotypes.\n",
    "6. *path_dataframe*: Path to the csv dataframe where data about each well such as the boolean phenotypes is going to be.\n",
    "7. *masks_names*: It expects a dictionary of key=str and value=list. Each interior list must contain a set of roi files to create a unified mask that will be segmented afterwards The key name of this list will represent the identifier name of the mask. This means if you want to segment the fish outline dorsal joining that roi file with the rois from the eyes just add the following key -> value: 'outline_dorsal' -> ['fishoutline_dorsal', 'eye_up_dorsal', 'eye_down_dorsal']. Atention!: It is mandatory for the masks names to end with \\_lat or \\_dor to indicate whether the mask will belong to lateral or dorsal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plate_path = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_GB_CPU_01V1/WP4_Developmental_terato/20210831_GB_CPU_01/20210831_GB_CPU_01_PLATE1/20210831_GB_CS_CPU_01_PLATE1/'\n",
    "#plate_path = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_GB_CPU_01V1/WP4_Developmental_terato/20210831_GB_CPU_01/20210831_GB_CPU_01_PLATE2_PC/20210831_GB_CS_CPU_01_PLATE2_PC'\n",
    "#plate_path = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_GB_CPU_01V1/WP4_Developmental_terato/20210831_GB_CPU_01/20210831_GB_CPU_01_PLATE3/20210831_GB_CS_CPU_01_PLATE3'\n",
    "#plate_path = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_GB_CPU_01V1/WP4_Developmental_terato/20210831_GB_CPU_01/20210831_GB_CPU_01_PLATE4/20210831_GB_CS_CPU_01_PLATE4'\n",
    "\n",
    "# what have we run so far: \n",
    "# all plates in: \n",
    "# p = \"/Volumes/GoogleDrive/Shared drives/AREA_SCI_2019/ZC_2019_JG_BATTELLE_PART2/DCA_VALIDATION/20210915_BATT2_DCA_DS\"\n",
    "\n",
    "#/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/WP2_magt1/20211019_SARP/20211019_SARP_CS_P1\n",
    "\n",
    "# test folder \n",
    "# plate_paths = ['/Users/sylviadyballa/Documents/BAT_test/20210831_GB_CS_CPU_01_PLATE1']\n",
    "\n",
    "# plate_paths = ['/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/WP2_magt1/raw_data/20211019_SARP/20211019_SARP_CS_P1']\n",
    "\n",
    "# plate_paths = ['/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_THANEE/20211026_srrm3_P1', \n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_THANEE/20211026_srrm3_P2', \n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_THANEE/20211026_srrm3_P3'\n",
    "#     ]\n",
    "\n",
    "# p = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_KT_TP_01V3/20211120_KTTP'\n",
    "# plate_paths = [item for item in os.listdir(p) if 'PLATE' in item]\n",
    "# ['20211120_ACYCLOVIR_CS_PLATE1',\n",
    "#  '20211120_ABACAVIRsulfate_CS_PLATE1',\n",
    "#  '20211120_DEAB_CS_PLATE1',\n",
    "#  '20211120_FLAVIDIRAVIR_CS_PLATE1',\n",
    "#  '20211120_NIFEDIPINE_CS_PLATE1',\n",
    "#  '20211120_GANCICLOUIR_CS_PLATE1',\n",
    "#  '20211121_ACYCLOVIRABA_CS_PLATE2',\n",
    "#  '20211121_GANCICLOVIRACYCLOVIR_CS_PLATE1']\n",
    "\n",
    "# # xris\n",
    "# plate_paths = ['/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/alg2/20211005_SA_RP_VAST_PLATE1',\n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/alg2/20211005_SA_RP_VAST_PLATE2',\n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/ctps1a/20211005_SA_RP_ctps1a/20211006_SARP_CS_P1',\n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/flt4/20211020_SARPflt4_CS_R1/',\n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/magt1/20211019_SARP_CS_P1/',\n",
    "#     '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/DevTerato/ppox/20220125_SARP_ppox_P1',\n",
    "#     ]\n",
    "\n",
    "# michele\n",
    "# p = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2022/ZC_2022_TN_MGC_01/20220309_Dev_Terato/ZC_2022_TN_MGC_01V'\n",
    "# plates = [item for item in os.listdir(p) if '202' in item]\n",
    "# plate_paths = [os.path.join(p, item) for item in plates]\n",
    "# plate_paths = ['/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/WP2_AND_5_ppox/raw data/20220125_second_VAST/20220125_SARP_ppox/20220125_SARP_ppox_P1']\n",
    "\n",
    "# BAT plates\n",
    "p = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images'\n",
    "plates = [item for item in os.listdir(p) if '202' in item]\n",
    "len(plates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images/20220226_1111_DS_R3',\n",
       " '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images/20220226_1240_DS_R3',\n",
       " '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images/20220226_1247_DS_R3',\n",
       " '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images/20220226_1323_DS_R3',\n",
       " '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_JG_BATTELLE_PART2/VAST_images/20220226_1656_DS_R3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run only plates that have no prediction\n",
    "plates = [\n",
    "    '',\n",
    "    '',\n",
    "    '',\n",
    "    '',\n",
    "    '',\n",
    "    ]\n",
    "\n",
    "plate_paths = [os.path.join(p, item) for item in plates]\n",
    "\n",
    "plate_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove roi files\n",
    "\n",
    "\n",
    "# # plate_paths &\n",
    "# # remove roi files\n",
    "# p = \"/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_SA_RP_01v01/WP2_AND_5_ppox/raw data/20211110_SARP_pox/SARP_PPOX/20211110_ppox_CS_P1\"\n",
    "\n",
    "# p = '/Volumes/GoogleDrive/Shared drives/AREA_SCI_2021/ZC_2021_KT_TP_01V3/20211120_KTTP'\n",
    "# for root, dirs, files in os.walk(p, topdown=True): \n",
    "#     for name in files: \n",
    "#         if name.endswith('.roi'): \n",
    "#             pass\n",
    "#             # print(os.path.join(root, name))\n",
    "#             print(name)\n",
    "#             # os.remove(os.path.join(root, name))\n",
    "\n",
    "\n",
    "# plate_paths = []\n",
    "# for root, dirs, files in os.walk(p, topdown=True): \n",
    "#     for name in dirs: \n",
    "#         if '_DS_' in name: \n",
    "#             plate_paths.append(os.path.join(root, name))         \n",
    "# print(len(plate_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! gpu is not available and the model will be predicting in cpu. This could be extremely slow.\n",
      "working with:  20220313_DEMARCONEDELTA_SD_R1 ,  1  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [08:58<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time predict masks 291.4519553184509\n",
      "Time area 0.14354586601257324\n",
      "Time length 0.16818833351135254\n",
      "Time genererate rois 127.11377835273743\n",
      "Time predict bools 116.85938549041748\n",
      "finished\n",
      "working with:  20220313_DEAB_SD_R1 ,  2  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/96 [00:36<05:12,  3.63s/it]\n",
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df arraly length issue - need to fix at some point....\n",
      "finished\n",
      "working with:  20220313_LILIAL_SD_R1 ,  3  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [08:30<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time predict masks 272.71672916412354\n",
      "Time area 0.14450669288635254\n",
      "Time length 0.17010068893432617\n",
      "Time genererate rois 112.93298029899597\n",
      "Time predict bools 119.01882028579712\n",
      "finished\n",
      "working with:  20220313_IBBALPL_SD_R1 ,  4  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [14:19<00:00,  8.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time predict masks 648.040874004364\n",
      "Time area 0.13069415092468262\n",
      "Time length 0.1443943977355957\n",
      "Time genererate rois 106.09274578094482\n",
      "Time predict bools 99.65375804901123\n",
      "finished\n",
      "working with:  20220313_ETHYLSAFRANATE_SD_R1 ,  5  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [09:06<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time predict masks 285.3434946537018\n",
      "Time area 0.1496589183807373\n",
      "Time length 0.1754305362701416\n",
      "Time genererate rois 133.318767786026\n",
      "Time predict bools 122.18756771087646\n",
      "finished\n",
      "working with:  20220313_ENBE_SD_R1 ,  6  of  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [08:55<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time predict masks 289.5539095401764\n",
      "Time area 0.14255023002624512\n",
      "Time length 0.19095087051391602\n",
      "Time genererate rois 123.86630058288574\n",
      "Time predict bools 119.00103759765625\n",
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ INPUT ############\n",
    "# plate_path = '../raw_data/20190918_1975_CS_R3'\n",
    "batch_size = 4\n",
    "model_path_seg = './Model_masks/weights.pt'\n",
    "model_path_bools = './Model_pheno/weights.pt'\n",
    "pheno_names = ['bodycurvature',\n",
    "              'yolkedema',\n",
    "              'necrosis',\n",
    "              'tailbending',\n",
    "              'notochorddefects',\n",
    "              'craniofacialedema',\n",
    "              'scoliosis',\n",
    "              'snoutjawdefects']\n",
    "\n",
    "masks_names = {'outline_lat': ['fishoutline_lateral'],\n",
    "               'heart_lat': ['heart_lateral'],\n",
    "               'yolk_lat': ['yolk_lateral'],\n",
    "               'ov_lat': ['ov_lateral'],\n",
    "               'eyes_dor': ['eye_up_dorsal', 'eye_down_dorsal'],\n",
    "               'outline_dor': ['fishoutline_dorsal', 'eye_up_dorsal', 'eye_down_dorsal']}\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('Predictions will be using gpu')\n",
    "else:\n",
    "    print('Warning! gpu is not available and the model will be predicting in cpu. This could be extremely slow.')\n",
    "\n",
    "for p, plate_path in enumerate(plate_paths):\n",
    "    print('working with: ', os.path.split(plate_path)[1], ', ', p+1, ' of ', len(plate_paths))\n",
    "    path_dataframe = plate_path + '/stats.csv'\n",
    "\n",
    "    try: \n",
    "        Tox.generate_and_save_predictions(plate_path,\n",
    "                                    batch_size,\n",
    "                                    model_path_seg,\n",
    "                                    model_path_bools,\n",
    "                                    masks_names.keys(),\n",
    "                                    pheno_names,\n",
    "                                    device,\n",
    "                                    path_dataframe)\n",
    "    except ValueError: \n",
    "        print('df arraly length issue - need to fix at some point....') # todo: 20210923_183175_CS_R1 [6]?\n",
    "    \n",
    "    # except: \n",
    "    #     traceback.print_exc()\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNfaE7ij6DAE",
    "outputId": "c8800507-e4f8-4912-ee44-8338dabf60ae"
   },
   "outputs": [],
   "source": [
    "############ INPUT ############\n",
    "\n",
    "# plate_path = '../raw_data/20190918_1975_CS_R3'\n",
    "batch_size = 4\n",
    "model_path_seg = './Model_masks/weights.pt'\n",
    "model_path_bools = './Model_pheno/weights.pt'\n",
    "pheno_names = ['bodycurvature',\n",
    "              'yolkedema',\n",
    "              'necrosis',\n",
    "              'tailbending',\n",
    "              'notochorddefects',\n",
    "              'craniofacialedema',\n",
    "              'scoliosis',\n",
    "              'snoutjawdefects']\n",
    "\n",
    "path_dataframe = plate_path + '/stats.csv'\n",
    "\n",
    "masks_names = {'outline_lat': ['fishoutline_lateral'],\n",
    "               'heart_lat': ['heart_lateral'],\n",
    "               'yolk_lat': ['yolk_lateral'],\n",
    "               'ov_lat': ['ov_lateral'],\n",
    "               'eyes_dor': ['eye_up_dorsal', 'eye_down_dorsal'],\n",
    "               'outline_dor': ['fishoutline_dorsal', 'eye_up_dorsal', 'eye_down_dorsal']}\n",
    "\n",
    "\n",
    "\n",
    "############ CODE ############\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('Predictions will be using gpu')\n",
    "else:\n",
    "    print('Warning! gpu is not available and the model will be predicting in cpu. This could be extremely slow.')\n",
    "\n",
    "Tox.generate_and_save_predictions(plate_path,\n",
    "                                  batch_size,\n",
    "                                  model_path_seg,\n",
    "                                  model_path_bools,\n",
    "                                  masks_names.keys(),\n",
    "                                  pheno_names,\n",
    "                                  device,\n",
    "                                  path_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qhNqjxB6DAG"
   },
   "source": [
    "**Step 2 (Print predictions)**: In the previous chunk, the predictions for the whole plate are done as well as the extraction of some interesting data. Finally, we can see the predictions for each well. This code only needs as input a dictionary of names of wells and their parts to print the masks.\n",
    "\n",
    "1. *wells*: Dictionary of wells as keys and parts of the fish to plot the masks as values. Remark that fish parts must be one of ('eye_up_dorsal', 'eye_down_dorsal', 'fishoutline_dorsal', 'fishoutline_lateral', 'heart_lateral', 'yolk_lateral', 'ov_lateral')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-n7pWFiM6DAG",
    "outputId": "28ae8f5b-e900-4cd7-9a16-351718cb4d7d"
   },
   "outputs": [],
   "source": [
    "############ INPUT ############\n",
    "\n",
    "wells = {'Well_A01': ['fishoutline_dorsal', 'eye_down_dorsal', 'eye_up_dorsal', 'yolk_lateral']}\n",
    "\n",
    "\n",
    "\n",
    "############ CODE ############\n",
    "\n",
    "# Let's retrieve dictionaries with the predictions of the model\n",
    "dic_images, dic_feno = Tox.dict_from_xml(plate_path)\n",
    "\n",
    "\n",
    "dorsal_masks = ['eye_up_dorsal', 'eye_down_dorsal', 'fishoutline_dorsal']\n",
    "lateral_masks = ['fishoutline_lateral', 'heart_lateral', 'yolk_lateral', 'ov_lateral']\n",
    "cmaps = {'fishoutline_lateral':'Purples' , \n",
    "         'heart_lateral': 'Reds', \n",
    "         'yolk_lateral': 'Greens', \n",
    "         'ov_lateral': 'Blues', \n",
    "         'eye_up_dorsal':'Oranges', \n",
    "         'eye_down_dorsal':'Oranges', \n",
    "         'fishoutline_dorsal':'Purples'}\n",
    "\n",
    "for well, parts in wells.items():\n",
    "    # DORSAL IMAGE TO FIGURE 1\n",
    "    pred_path = os.path.join(plate_path, well, dic_images[well][0])\n",
    "    im = cv2.imread(pred_path)  # Read image ()\n",
    "    plt.figure(1)\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    # LATERAL IMAGE TO FIGURE 2\n",
    "    pred_path = os.path.join(plate_path, well, dic_images[well][1])\n",
    "    im = cv2.imread(pred_path)  # Read image ()\n",
    "    plt.figure(2)\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    for part in parts:\n",
    "        if part in dorsal_masks: plt.figure(1)\n",
    "        else: plt.figure(2)\n",
    "        roi_path = os.path.join(plate_path, well, part + '.roi')\n",
    "        roi = Tox.read_roi_file(roi_path)[part]\n",
    "        mask_img = np.zeros(im.shape, np.uint8)\n",
    "        mask_img = Tox.obtain_mask(mask_img, roi)\n",
    "        plt.imshow(mask_img, cmaps[part], alpha = 0.4)\n",
    "    \n",
    "    print(dic_feno[well])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix88Ottdc5f2"
   },
   "source": [
    "# Exploratory analysis\n",
    "\n",
    "Now that we have made all the predictions, we can plot our data in order to see some insights and provide a general view of the results obteined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyA3PwuhkKGg"
   },
   "source": [
    "Before plotting our data we must convert the predictions stored in the stats.csv file into a dataframe, which will be what we will use to process the data and graph them. Then we only need to call the functions of the graphics library and the graphics will be saved in the input folder\n",
    "\n",
    "The input parameters that we have to initialize to make the plots are:\n",
    "\n",
    "1.   *dataframe*: The stats.csv converted to a dataframe\n",
    "2.   *path_graphics*: the folder where we want to save the graphics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "error",
     "timestamp": 1624286483560,
     "user": {
      "displayName": "Andrea Garcia Valdés",
      "photoUrl": "",
      "userId": "11425704364991342656"
     },
     "user_tz": -120
    },
    "id": "c2HgtARbn6b_",
    "outputId": "14998881-3a68-492e-e09d-0bf065a02e7c"
   },
   "outputs": [],
   "source": [
    "############ INPUT ############\n",
    "\n",
    "#Our stats.csv has been saved in the path_dataframe variable\n",
    "dataframe = pd.read_csv(path_dataframe)\n",
    "path_graphics = plate_path \n",
    "\n",
    "\n",
    "############ CODE ###########\n",
    "\n",
    "#We just have to call the functions\n",
    "\n",
    "doseresponse(dataframe, path_graphics)\n",
    "Mca(dataframe, path_graphics)\n",
    "plots(dataframe, path_graphics)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ee445c29dedd4a71891f2f1d193108c19b2304a51a0cdac7aa1b226577bad998"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('toxeco': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
