{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "\n",
    "This notebook contains the information to run the training of the models for both mask and boolean features predictions. Both are based on DeepLab architectures with little modifications to adapt the neural networks to our specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports for the execution of the code.\n",
    "# Make sure you have previously executed requirements.txt\n",
    "\n",
    "'''\n",
    "# WARNING:\n",
    "\n",
    "Check https://pytorch.org/get-started/previous-versions/ and install the proper\n",
    "pytorch and torchvision versions according to your cuda version.\n",
    "\n",
    "You can figure out your cuda versions with:\n",
    "/usr/local/cuda/bin/nvcc --version\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import click\n",
    "import pickle\n",
    "import datahandler\n",
    "import sklearn.metrics\n",
    "import ETL_lib as Tox\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils import data\n",
    "from trainer import train_model\n",
    "from model import createDeepLabv3_resnet_50, binary_fenotypes_wideresnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 (Creation of masks):** We must first create the masks from the roi files in the folders. This will serve as targets in the training process.\n",
    "\n",
    "*Input:* Two folders paths and one list are expected:\n",
    "1. *raw_data_path*: Folder where all the data is. This data must contain several plate folders to train.\n",
    "\n",
    "2. *masks_path*: Destination folder where the masks will be saved for the training process. When the model has been trained, this folder will be automatically removed.\n",
    "\n",
    "3. *masks_names*: It expects a dictionary of key=str and value=list. Each interior list must contain a set of roi files to create a unified mask that will be segmented afterwards The key name of this list will represent the identifier name of the mask. This means if you want to segment the fish outline dorsal joining that roi file with the rois from the eyes just add the following key -> value: 'outline_dorsal' -> ['fishoutline_dorsal', 'eye_up_dorsal', 'eye_down_dorsal']. Atention!: It is mandatory for the masks names to end with \\_lat or \\_dor to indicate whether the mask will belong to lateral or dorsal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ INPUT ############\n",
    "\n",
    "raw_data_path = '../raw_data'\n",
    "data_path = '../processed_data'\n",
    "masks_names = masks_names = {'outline_lat': ['fishoutline_lateral'],\n",
    "                             'heart_lat': ['heart_lateral'],\n",
    "                             'yolk_lat': ['yolk_lateral'],\n",
    "                             'ov_lat': ['ov_lateral'],\n",
    "                             'eyes_dor': ['eye_up_dorsal', 'eye_down_dorsal'],\n",
    "                             'outline_dor': ['fishoutline_dorsal', 'eye_up_dorsal', 'eye_down_dorsal']}\n",
    "\n",
    "\n",
    "############ CODE ############\n",
    "\n",
    "# Let's check whether raw data path exist or not\n",
    "if os.path.exists(raw_data_path):\n",
    "    print('Generating masks folders...')\n",
    "    Tox.data_generation_pipeline(raw_data_path, data_path, masks_names)\n",
    "    print('Finished!')\n",
    "else:\n",
    "    print(raw_data_path, \"does not exist.\")\n",
    "\n",
    "with open(data_path + '/complete_fishes.pkl', 'rb') as pickle_file:\n",
    "    complete_list = pickle.load(pickle_file)\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 (DeepLab Training):** Once we have target data formatted to train our model (i.e extracted masks from rois) we can run DeepLab training. This process may take quite a long time depending on the used parameters (such as epochs or batch size).\n",
    "\n",
    "In order to take advantatge of the data of every single well (even of those which don't have all the rois) a two step training is carried out. The first step of training will be meant to be trained exclusively with the wells that have all the rois. Contrary, in the second training step, we will also use those uncomplete wells using as a target the predictions made by the model itself. This paradigm is a modification based on *Learning without forgetting* by Zhizhong Li and Derek Hoiem. In order to do that, the previous called function *generation_pipeline* generated a *pkl* file including all complete wells. This will be passed to datahandler to say: just charge this data for training. In the second phase no list will be passed so the dataloader will charge all wells instead. Note that this phase doesn't ensure an improvement in our model so just a pair of epochs are run. If the model worsens, the best model from the first phase is kept. \n",
    "\n",
    "Next we will define input parameters:\n",
    "1. *images_folder*: Folder where images are (path from data_path).\n",
    "2. *masks_folders*: Folders where masks are (path form data_path).\n",
    "3. *model_directory*: Directory where the model is going to be saved.\n",
    "4. *masks_weights*: Weights to applied to each mask. Note that weights lists must be the same length that masks_folders and weights ara applied in the same order. By default those weights have been chosen to accomplish some area criterions. For each mask the weights have been put to be mean(area)/mean(max_area). So the greater mask will have weight one.\n",
    "5. *criterion*: Loss function to be used in the model.\n",
    "6. *optimizer*: Optimizer for the model.\n",
    "7. *metrics*: Metrics to be used in the evaluation of the model.\n",
    "8. *seed*: Seed for the model.\n",
    "9. *fraction*: Fraction of the data to be used in test.\n",
    "10. *batch_size*: Batch size\n",
    "11. *num_epochs*: Number of epochs for the first phase.\n",
    "12. *num_epochs2*: Number of epochs for the second phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# NOTES:\n",
    "\n",
    "-Batch size needs to be larger than one due to the batch normalization.\n",
    "\n",
    "-The chosen loss funcion (nn.BCEWithLogitsLoss()) applies a sigmoid to the\n",
    "output ans then applies the binary cross entropy loss function (a pixel belongs\n",
    "to a class or doesn't)\n",
    "\n",
    "This first part of the code is responsible to define where data is found and\n",
    "where the model is going to be saved. In order to do that a main data directory\n",
    "must be declared. Inside the this directory an image folder must exists with\n",
    "all the raw images and the folders with the different masks containg the masks\n",
    "with the exact same name of their corresponding original image:\n",
    "\n",
    "                     ___________data_path _____________\n",
    "                    /               |                  \\\n",
    "                Images       Mask1_folder  ...  Maskn_folder\n",
    "                  |                 |                  |\n",
    "              img1.png          img1.png           img1.png\n",
    "                  .                 .                  .\n",
    "                  .                 .                  .\n",
    "                  .                 .                  .\n",
    "              imgk.png          imgk.png           imgk.png\n",
    "\n",
    "\n",
    "If the step 1 cell has been executed, this configuration is ensured.\n",
    "'''\n",
    "\n",
    "############ INPUT ############\n",
    "\n",
    "# Define images path and masks paths from data_path\n",
    "images_folder = 'Images'\n",
    "masks_folders = list(masks_names.keys())\n",
    "\n",
    "# Path from current path to save the generated model\n",
    "model_directory = Path('./Model_masks')\n",
    "if not model_directory.exists():\n",
    "    model_directory.mkdir()\n",
    "    \n",
    "\n",
    "# Model parameters\n",
    "\n",
    "# Creation of the model\n",
    "model = createDeepLabv3_resnet_50(outputchannels=len(masks_folders))\n",
    "\n",
    "masks_weights = torch.tensor([[[0.5, 2, 2, 2, 1, 0.5]]])\n",
    "### Transformation of masks_weights to correct format:\n",
    "masks_weights = masks_weights.repeat_interleave(190, dim=1)\n",
    "masks_weights = masks_weights.repeat_interleave(1024, dim=0).transpose(0,2)\n",
    "if torch.cuda.is_available():\n",
    "    masks_weights = masks_weights.to(torch.device('cuda:0'))\n",
    "\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean',\n",
    "                                       pos_weight = masks_weights) # Specify the loss function\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Specify the optimizer\n",
    "                                                           # with a low learning rate\n",
    "\n",
    "# Specify the evaluation metrics\n",
    "metrics = {'f1_score': sklearn.metrics.f1_score}\n",
    "           #'auroc': sklearn.metrics.roc_auc_score}\n",
    "           #'accuracy_score': sklearn.metrics.accuracy_score}\n",
    "\n",
    "seed = 1\n",
    "fraction = 0.2\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "num_epochs2 = 3\n",
    "\n",
    "\n",
    "        \n",
    "############ CODE ############\n",
    "\n",
    "# CREATE WEIGHTS TENSOR STRUCTURE FOR TRAINING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FIRST TRAINING PHASE\n",
    "\n",
    "# Ceation of the data loaders ['Train', 'Test']\n",
    "dataloaders, image_datasets = datahandler.get_dataloader_single_folder(data_path,\n",
    "                                                       images_folder,\n",
    "                                                       masks_folders,\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       seed = seed,\n",
    "                                                       fraction = fraction,\n",
    "                                                       images_list = complete_list)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "best_loss = train_model(model,\n",
    "                criterion,\n",
    "                dataloaders,\n",
    "                optimizer,\n",
    "                bpath = model_directory,\n",
    "                masks_names = masks_folders,\n",
    "                metrics = metrics,\n",
    "                num_epochs = num_epochs,\n",
    "                device = device)\n",
    "\n",
    "\n",
    "\n",
    "# SECOND TRAINING PHASE\n",
    "\n",
    "dataloaders2, _ = datahandler.get_dataloader_single_folder(data_path,\n",
    "                                                       images_folder,\n",
    "                                                       masks_folders,\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       fraction = fraction,\n",
    "                                                       test_list = getattr(image_datasets['Test'],'image_names'))\n",
    "\n",
    "# Train the model\n",
    "_ = train_model(model,\n",
    "                criterion,\n",
    "                dataloaders,\n",
    "                optimizer,\n",
    "                bpath = model_directory,\n",
    "                masks_names = masks_folders,\n",
    "                metrics = metrics,\n",
    "                num_epochs = 2,\n",
    "                device = device,\n",
    "                best_loss = best_loss)\n",
    "\n",
    "torch.save(model, model_directory / 'weights.pt')\n",
    "\n",
    "# Alternatively you can upload an already trained model:\n",
    "# torch.load(model_directory + 'weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Phenotypes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 (DeepLab Training):** Let's train the model for the boolean phenotypes. As in the semantic segmentation model, this one is also based on DeepLab architecture but adding a fully connected network in the output of the convolutional neural network.\n",
    "\n",
    "We must take into account that given the nature of the available data to train our models, it has been impossible to train an accurate network for the *otholitsdefects* variable. Consequently, we have removed this phenotype as it was adding some bias to the overall model worsening the behavior of the predictions of the other variables.\n",
    "\n",
    "The input parameters to execute the training are:\n",
    "\n",
    "1. *pheno_names*: A list with the name of the phenotypes to predict.\n",
    "2. *model_directory*: Directory where the model is going to be saved.\n",
    "3. *class_weights*: Weight given to each class.\n",
    "4. *positive_weights*: Penalization for false negative for each class.\n",
    "5. *criterion*: Loss function to be used in the model.\n",
    "6. *optimizer*: Optimizer for the model.\n",
    "7. *metrics*: Metrics to be used in the evaluation of the model.\n",
    "8. *seed*: Seed for the model.\n",
    "9. *fraction*: Fraction of the data to be used in test.\n",
    "10. *batch_size*: Batch size\n",
    "11. *acum_steps*: Accumulable steps to apply backpropagation.\n",
    "12. *num_epochs*: Number of epochs for the first phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ INPUT ############\n",
    "\n",
    "pheno_names = ['bodycurvature',\n",
    "               'yolkedema',\n",
    "               'necrosis',\n",
    "               'tailbending',\n",
    "               'notochorddefects',\n",
    "               'craniofacialedema',\n",
    "               'finabsence',\n",
    "               'scoliosis',\n",
    "               'snoutjawdefects']\n",
    "\n",
    "# Path from current path to save the generated model\n",
    "model_directory = Path('./Model_pheno')\n",
    "if not model_directory.exists():\n",
    "    model_directory.mkdir()\n",
    "    \n",
    "\n",
    "# Model Parameters\n",
    "\n",
    "# Creation of the model\n",
    "model = binary_fenotypes_wideresnet50(len(pheno_names))\n",
    "    \n",
    "class_weights = [1/len(pheno_names) for i in pheno_names]\n",
    "\n",
    "positive_weights = [1, 1, 1, 1, 10, 1, 10, 1, 1]\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='none',pos_weight = positive_weights) # Specify the loss function\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5, \n",
    "                                                 weight_decay = 1e-5) # Specify the optimizer\n",
    "                                                                      # with a low learning rate\n",
    "\n",
    "metrics = {'f1_score': sklearn.metrics.f1_score,\n",
    "           'precision': sklearn.metrics.precision_score,\n",
    "           'recall': sklearn.metrics.recall_score}\n",
    "\n",
    "seed = 1\n",
    "fraction = 0.2\n",
    "batch_size = 4\n",
    "acum_steps = 64\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "        \n",
    "############ CODE ############\n",
    "\n",
    "'''\n",
    "Given a list of image names, filters it by only keeping the fish_names with\n",
    "all the boolean phenotypes in feno_names\n",
    "'''\n",
    "stats_path = data_path + '/stats.csv'\n",
    "complete_bools = Tox.filter_by_bool(complete_list, pheno_names, stats_path)\n",
    "\n",
    "# Ceation of the data loaders ['Train', 'Test']\n",
    "dataloaders, image_datasets = datahandler.get_dataloader_single_folder_bool(data_dir = data_path,\n",
    "                                                       image_folder = images_path,\n",
    "                                                       feno_names = pheno_names,\n",
    "                                                       model_folder = model_directory,\n",
    "                                                       image_list = complete_bools,\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       seed = seed,\n",
    "                                                       fraction = fraction)\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING PHASE\n",
    "\n",
    " _ = train_clasif_model(model,\n",
    "                     feno_names,\n",
    "                     criterion,\n",
    "                     dataloaders,\n",
    "                     optimizer,\n",
    "                     bpath = model_directory,\n",
    "                     metrics = metrics,\n",
    "                     num_epochs = num_epochs,\n",
    "                     bs = batch_size,\n",
    "                     batch_acum = acum_steps,\n",
    "                     class_weights = class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
